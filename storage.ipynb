{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 적절한 형태소 분석기 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우수한 형태소 분석기 추출 => 결과 hanNouns\n",
    "\n",
    "\n",
    "#-- 기본 개념 --#\n",
    "# morphs 형태소 단위\n",
    "# nouns 단어\n",
    "# pos 텍스트에 품사정보 포함\n",
    "\n",
    "#-- Hannanum --#\n",
    "hannanum = Hannanum()\n",
    "hanMorphs = hannanum.morphs(doc)\n",
    "hanNouns = hannanum.nouns(doc)\n",
    "hanPos = hannanum.pos(doc)\n",
    "\n",
    "#-- kkma --#\n",
    "kkma = Kkma()\n",
    "kkmaMorphs = kkma.morphs(doc)\n",
    "kkmaNouns = kkma.nouns(doc)\n",
    "kkmaPos = kkma.pos(doc)\n",
    "\n",
    "#-- Okt --#\n",
    "okt = Okt()\n",
    "oktMorphs = okt.morphs(doc)\n",
    "oktNouns = okt.nouns(doc)\n",
    "oktPos = okt.pos(doc)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "finish = {}\n",
    "for num, testType in enumerate([hanMorphs,hanNouns,kkmaMorphs,kkmaNouns,oktMorphs,oktNouns]) :\n",
    "    words = ' '.join(testType)\n",
    "    vect = CountVectorizer(ngram_range=(1,2))\n",
    "    count = vect.fit([words])\n",
    "\n",
    "    candidate = count.get_feature_names_out()\n",
    "    doc_embedding = model.encode([doc])\n",
    "    candidate_embeddings = model.encode(candidate)\n",
    "\n",
    "    distances = cosine_similarity(doc_embedding,candidate_embeddings)\n",
    "    # result = candidate[distances.argsort()[0][-5:]]\n",
    "    result = mmr(doc_embedding, candidate_embeddings, candidate, top_n=50, diversity=0.2)\n",
    "    finish[num] = result\n",
    "\n",
    "\n",
    "### 최종선택 hanNouns\n",
    "### 최종선택 hanNouns\n",
    "### 최종선택 hanNouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 크롤러 예전버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kyoboExtract(ISBN:str) -> dict : \n",
    "    kyoboUrl = f'http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode={ISBN}'\n",
    "    kyoboHtml = requests.get(kyoboUrl)\n",
    "    kyoboSoup = BeautifulSoup(kyoboHtml.content)\n",
    "\n",
    "    #-- title --#\n",
    "    bookTitle : str = kyoboSoup.h1.strong.string.strip()\n",
    "\n",
    "    #-- book Intro --#\n",
    "    bookIntro : str = kyoboSoup.find('div',{'class':'box_detail_article'}).string.strip()\n",
    "\n",
    "    #-- author Intro --#\n",
    "    authorIntro : str = kyoboSoup.find('div',{'class' : 'box_detail_article'}).string.strip()\n",
    "\n",
    "    #-- keywords --#\n",
    "    keywords = kyoboSoup.find('div',{'class':'tag_list'}).find_all('a')\n",
    "    keywords : list = [k.string.replace('#','') for k in keywords]\n",
    "\n",
    "    #-- TOC --#\n",
    "    toc = kyoboSoup.find_all('div',{'class' : 'box_detail_article'})[3]\n",
    "    toc = re.sub('<.*?>|\\\\t','',str(toc))\n",
    "    toc = re.sub('\\\\n',' ',toc)\n",
    "    toc :str = re.sub('\\\\r',',',toc)\n",
    "    toc = re.sub('\\d[.]|\\d|[,]\\s*','',toc) \n",
    "    \n",
    "    return dict(bookTitle=bookTitle,bookIntro=bookIntro,authorIntro=authorIntro,toc=toc,keywords=keywords)\n",
    "\n",
    "\n",
    "kyoboExtract(9791160505979)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lib info extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangwoolee/Library/Python/3.8/lib/python/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_excel('./data/lib_info.xlsx',)\n",
    "a = a[6:]\n",
    "a.columns = a.iloc[0]\n",
    "a = a[1:]\n",
    "a = a[['도서관명','도서관코드']].reset_index(drop=True)\n",
    "a.columns= ['libName','libCode']\n",
    "a.to_csv('./data/lib_info.csv',encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "dataList=os.listdir(path='./data/libbooks/')\n",
    "\n",
    "# 결과 종합하기\n",
    "result = []\n",
    "for num,dataName in enumerate(dataList) :\n",
    "\n",
    "    # 불러오기\n",
    "    itemCol = ['도서명','저자','출판사','발행년도','ISBN','주제분류번호','도서권수','대출건수','등록일자']\n",
    "    LibBook = pd.read_csv(f'./data/libbooks/{dataName}',encoding='CP949',usecols=itemCol)\n",
    "\n",
    "    #필터링\n",
    "    BM = LibBook['등록일자'] > '2018-01-01'\n",
    "    LibBook = LibBook[BM]\n",
    "\n",
    "    # 004,005 분류하기\n",
    "    k = LibBook['주제분류번호'].astype(str)\n",
    "    item= k[k.str.contains('004.')].index.tolist()\n",
    "    itemAppend=k[k.str.contains('005.')].index.tolist()\n",
    "    item.extend(itemAppend)\n",
    "\n",
    "    #booklist 만들기 \n",
    "    bookList=LibBook[LibBook.index.isin(item)]\n",
    "    bookList['도서관ID'] =num\n",
    "    result.append(bookList)\n",
    "\n",
    "# Concat & Save BookListRaw\n",
    "final = pd.concat(result).reset_index(drop=True)\n",
    "final.to_csv('./data/bookListRaw.csv',encoding='CP949')\n",
    "\n",
    "# Save BookList\n",
    "b = final.drop_duplicates(subset='ISBN')\n",
    "dropDuplicate = b[['도서명','저자','출판사','ISBN','주제분류번호','등록일자']].reset_index(drop=True)\n",
    "\n",
    "dropDuplicate.to_csv('./data/bookListSearch',encoding='CP949')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
