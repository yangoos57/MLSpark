{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 적절한 형태소 분석기 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우수한 형태소 분석기 추출 => 결과 hanNouns\n",
    "\n",
    "\n",
    "#-- 기본 개념 --#\n",
    "# morphs 형태소 단위\n",
    "# nouns 단어\n",
    "# pos 텍스트에 품사정보 포함\n",
    "\n",
    "#-- Hannanum --#\n",
    "hannanum = Hannanum()\n",
    "hanMorphs = hannanum.morphs(doc)\n",
    "hanNouns = hannanum.nouns(doc)\n",
    "hanPos = hannanum.pos(doc)\n",
    "\n",
    "#-- kkma --#\n",
    "kkma = Kkma()\n",
    "kkmaMorphs = kkma.morphs(doc)\n",
    "kkmaNouns = kkma.nouns(doc)\n",
    "kkmaPos = kkma.pos(doc)\n",
    "\n",
    "#-- Okt --#\n",
    "okt = Okt()\n",
    "oktMorphs = okt.morphs(doc)\n",
    "oktNouns = okt.nouns(doc)\n",
    "oktPos = okt.pos(doc)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "finish = {}\n",
    "for num, testType in enumerate([hanMorphs,hanNouns,kkmaMorphs,kkmaNouns,oktMorphs,oktNouns]) :\n",
    "    words = ' '.join(testType)\n",
    "    vect = CountVectorizer(ngram_range=(1,2))\n",
    "    count = vect.fit([words])\n",
    "\n",
    "    candidate = count.get_feature_names_out()\n",
    "    doc_embedding = model.encode([doc])\n",
    "    candidate_embeddings = model.encode(candidate)\n",
    "\n",
    "    distances = cosine_similarity(doc_embedding,candidate_embeddings)\n",
    "    # result = candidate[distances.argsort()[0][-5:]]\n",
    "    result = mmr(doc_embedding, candidate_embeddings, candidate, top_n=50, diversity=0.2)\n",
    "    finish[num] = result\n",
    "\n",
    "\n",
    "### 최종선택 hanNouns\n",
    "### 최종선택 hanNouns\n",
    "### 최종선택 hanNouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 크롤러 예전버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kyoboExtract(ISBN:str) -> dict : \n",
    "    kyoboUrl = f'http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode={ISBN}'\n",
    "    kyoboHtml = requests.get(kyoboUrl)\n",
    "    kyoboSoup = BeautifulSoup(kyoboHtml.content)\n",
    "\n",
    "    #-- title --#\n",
    "    bookTitle : str = kyoboSoup.h1.strong.string.strip()\n",
    "\n",
    "    #-- book Intro --#\n",
    "    bookIntro : str = kyoboSoup.find('div',{'class':'box_detail_article'}).string.strip()\n",
    "\n",
    "    #-- author Intro --#\n",
    "    authorIntro : str = kyoboSoup.find('div',{'class' : 'box_detail_article'}).string.strip()\n",
    "\n",
    "    #-- keywords --#\n",
    "    keywords = kyoboSoup.find('div',{'class':'tag_list'}).find_all('a')\n",
    "    keywords : list = [k.string.replace('#','') for k in keywords]\n",
    "\n",
    "    #-- TOC --#\n",
    "    toc = kyoboSoup.find_all('div',{'class' : 'box_detail_article'})[3]\n",
    "    toc = re.sub('<.*?>|\\\\t','',str(toc))\n",
    "    toc = re.sub('\\\\n',' ',toc)\n",
    "    toc :str = re.sub('\\\\r',',',toc)\n",
    "    toc = re.sub('\\d[.]|\\d|[,]\\s*','',toc) \n",
    "    \n",
    "    return dict(bookTitle=bookTitle,bookIntro=bookIntro,authorIntro=authorIntro,toc=toc,keywords=keywords)\n",
    "\n",
    "\n",
    "kyoboExtract(9791160505979)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lib info extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangwoolee/Library/Python/3.8/lib/python/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_excel('./data/lib_info.xlsx',)\n",
    "a = a[6:]\n",
    "a.columns = a.iloc[0]\n",
    "a = a[1:]\n",
    "a = a[['도서관명','도서관코드']].reset_index(drop=True)\n",
    "a.columns= ['libName','libCode']\n",
    "a.to_csv('./data/lib_info.csv',encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Response로 정보 얻는건 불가능\n",
    "import requests\n",
    "import ast\n",
    "lib_info = pd.read_csv('./data/lib_info.csv',encoding='CP949',index_col=0)\n",
    "lib_info[lib_info['libName'].str.contains('양천')]\n",
    "\n",
    "key = '7123eacb2744a02faca2508a82304c3bf154bf0b285da35c2faa2b8498b09872'\n",
    "libCode=lib_info['libCode'][104]\n",
    "start='2018-01-01'\n",
    "end='2022-06-30'\n",
    "response = requests.get(f'http://data4library.kr/api/itemSrch?authKey={key}&libCode={libCode}&startDt={start}&endDt={end}&format=JSON&pageSize=100')\n",
    "\n",
    "\n",
    "\n",
    "a = ast.literal_eval(str(response.content.decode('utf-8')))\n",
    "\n",
    "a\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
