{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from bookutils import *\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from konlpy.tag import Hannanum\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from keybert import KeyBERT\n",
    "from sklearn.cluster import KMeans\n",
    "bookInfo = pd.read_parquet('./data/bookInfo.parquet')\n",
    "stopwords = pd.read_csv('./data/stopwords.csv').T.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList = bookInfo[bookInfo['col1'] == 9791160508796].astype(str).values.tolist()[0]\n",
    "text = re.sub(\"\\d[.]|\\d|\\W|[_]\", \" \", ''.join(textList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyBertModel = KeyBERT('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "# model = KeyBERT('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = keyBertModel.extract_keywords(text,top_n=20,keyphrase_ngram_range=(1,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### keybert => 20개 추림 => 이거가지고 encoding => clustering ㄲ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react = bookInfo[bookInfo['col0'].str.contains('리액트')]['col1'].tolist()\n",
    "python = bookInfo[bookInfo['col0'].str.contains('파이썬')]['col1'].tolist()\n",
    "docker = bookInfo[bookInfo['col0'].str.contains('도커')]['col1'].tolist()\n",
    "\n",
    "python.extend(docker)\n",
    "react.extend(python)\n",
    "\n",
    "testBooks = bookInfo[bookInfo['col1'].isin(react)]\n",
    "\n",
    "len(testBooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "testBooks = bookInfo.iloc[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in list(range(len(testBooks))):\n",
    "    doc = testBooks.iloc[i].astype(str).values.tolist()\n",
    "    text = ' '.join(doc)\n",
    "    keyValues = bookInfoExtraction(text,stopwords,model)\n",
    "    result.append(keyValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 문장 전체로 encode 해본 테스트\n",
    "result = []\n",
    "for i in list(range(100,150)) :\n",
    "    textList = bookInfo.iloc[i].astype(str).values.tolist()\n",
    "    text = re.sub(\"\\d[.]|\\d|\\W|[_]\", \" \", ''.join(textList))\n",
    "    result.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster0\n",
      "['Real MySQL 8.0 (2권)', 'Real MySQL 8.0 (1권)']\n",
      "cluster1\n",
      "['구글 BERT의 정석', '기초부터 실무 응용까지', '디버깅을 통해 배우는 리눅스 커널의 구조와 원리 2', '디버깅을 통해 배우는 리눅스 커널의 구조와 원리 1', '파이썬이 보이는 그림책', '자바가 보이는 그림책', '실전 아파치 카프카', '쿠버네티스 완벽 가이드', '생활코딩! React 리액트 프로그래밍', 'OS가 보이는 그림책', '윤성우의 열혈 파이썬 중급편']\n",
      "cluster2\n",
      "['UX 디자인이 처음이라면', '머신러닝 디자인 패턴', '일 잘하는 직장인을 위한', '오라클 튜닝 에센셜', '온택트 파워포인트 속성과외', '단위 테스트', '백견불여일타 스프링 부트 쇼핑몰 프로젝트 with JPA', '홍마리오의 워드프레스 입문 + 실전(종합편)', '퀀트 투자를 위한 머신러닝·딥러닝 알고리듬 트레이딩 2/e', 'AI의 얼개를 기본부터 설명한', '파이썬 GUI 프로그래밍 쿡북', '맛있는 디자인 망고보드', '딥러닝 텐서플로 교과서', '필요할 때 바로 써먹는 인디자인 실용테크닉', '필요할 때 바로 써먹는', 'Python으로 배우는 문제해결과 인공지능', '이펙티브 타입스크립트', '스벨트 앤 새퍼 인 액션', '맛있는 디자인 포토샵 CC 2021', '맛있는 디자인']\n",
      "cluster3\n",
      "['데이터 스토리텔링 연습', '쉽게 시작하는 캐글 데이터 분석', '자바 데이터 분석', '3일 만에 끝내는 코딩 통계', '데이터 스토리', '데이터 사이언스의 매력', '엑셀로 하는 데이터 분석', '데이터 과학을 위한 통계', '데이터 해석학 입문']\n",
      "cluster4\n",
      "['리액트 네이티브를 다루는 기술', '엘라스틱 스택 개발부터 운영까지', '피닉스 프로젝트', 'fastai와 파이토치가 만나 꽃피운 딥러닝', '쿠버네티스 입문', '가상 면접 사례로 배우는 대규모 시스템 설계 기초', '처음 시작하는 마이크로서비스', '엔터프라이즈 환경을 위한 마이크로서비스']\n"
     ]
    }
   ],
   "source": [
    "doc_embedding = model.encode(result)\n",
    "num_clusters =5\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(doc_embedding)\n",
    "\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "data = pd.DataFrame([testBooks['col0'].tolist(),cluster_assignment]).T\n",
    "data.columns = ['name','cluster_n']\n",
    "for i in list(range(num_clusters)) :\n",
    "    print(f'cluster{i}')\n",
    "    print(data[data['cluster_n']==i]['name'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elbow 적용해서 해보면 좋은 결과가 나올 수 있을듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 핵심단어 20개 추출 후 bert 결과 bookInfo[100:150]\n",
    "# cluster0\n",
    "# ['디버깅을 통해 배우는 리눅스 커널의 구조와 원리 1', 'OS가 보이는 그림책']\n",
    "# cluster1\n",
    "# ['리액트 네이티브를 다루는 기술', '구글 BERT의 정석', '기초부터 실무 응용까지', '백견불여일타 스프링 부트 쇼핑몰 프로젝트 with JPA', '자바가 보이는 그림책', '피닉스 프로젝트', '딥러닝 텐서플로 교과서', 'Python으로 배우는 문제해결과 인공지능', '처음 시작하는 마이크로서비스', '맛있는 디자인 포토샵 CC 2021', '맛있는 디자인', '생활코딩! React 리액트 프로그래밍', '엔터프라이즈 환경을 위한 마이크로서비스']\n",
    "# cluster2\n",
    "# ['UX 디자인이 처음이라면', '머신러닝 디자인 패턴', '필요할 때 바로 써먹는 인디자인 실용테크닉', '가상 면접 사례로 배우는 대규모 시스템 설계 기초']\n",
    "# cluster3\n",
    "# ['일 잘하는 직장인을 위한', '데이터 스토리텔링 연습', '쉽게 시작하는 캐글 데이터 분석', '자바 데이터 분석', '3일 만에 끝내는 코딩 통계', '퀀트 투자를 위한 머신러닝·딥러닝 알고리듬 트레이딩 2/e', '데이터 스토리', '데이터 사이언스의 매력', 'Real MySQL 8.0 (1권)', '엑셀로 하는 데이터 분석', '실전 아파치 카프카', '데이터 과학을 위한 통계', '데이터 해석학 입문']\n",
    "# cluster4\n",
    "# ['오라클 튜닝 에센셜', '디버깅을 통해 배우는 리눅스 커널의 구조와 원리 2', '온택트 파워포인트 속성과외', '엘라스틱 스택 개발부터 운영까지', '단위 테스트', '파이썬이 보이는 그림책', '홍마리오의 워드프레스 입문 + 실전(종합편)', 'AI의 얼개를 기본부터 설명한', 'fastai와 파이토치가 만나 꽃피운 딥러닝', '파이썬 GUI 프로그래밍 쿡북', '맛있는 디자인 망고보드', 'Real MySQL 8.0 (2권)', '필요할 때 바로 써먹는', '쿠버네티스 입문', '쿠버네티스 완벽 가이드', '이펙티브 타입스크립트', '스벨트 앤 새퍼 인 액션', '윤성우의 열혈 파이썬 중급편']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두가지 실험을 해보자.\n",
    "# 1. embedding 된 문장을 넣어서 구분시키기 kmeans 사용\n",
    "# 2. keyword를 뽑은다음 단어를 vector화 한 뒤 kmeans 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['최적화', '문제', '유니티', '게임', '성능', '프로그래밍', '하드웨어', '요약', '엔진', '기술', '병목현상', '시스템', '메모리', '자원', '배칭', '분석', '결함', '프로파일링', '관리', '소개']\n"
     ]
    }
   ],
   "source": [
    "# def testbookInfoExtraction(doc: str, stopwords: list, model) -> list:\n",
    "#     \"\"\"\n",
    "#     반복적으로 모델을 불러와야하는 문제를 개선하기 위해 변수에 model을 넣었음.\n",
    "#     모델을 미리 불러와야 한다.\n",
    "#     리턴 값으로 keyword를 반환함.\n",
    "#     \"\"\"\n",
    "#     start_in = time.time()\n",
    "#     doc: str = (\n",
    "#         # re.sub(\"[_-]|\\d[.]|\\d|[▶★●]\", \"\", doc)\n",
    "#         re.sub(\"\\d[.]|\\d|\\W|[_]\", \" \", doc)\n",
    "#         .replace(\"머신 러닝\", \"머신러닝\")\n",
    "#         .replace(\"인공 지능\", \"인공지능\")\n",
    "#     )\n",
    "#     text = list(filter(None, doc.split(\" \")))\n",
    "#     removedoc = removeStopwords(text, stopwords)\n",
    "\n",
    "#     # 문서 정보 추출\n",
    "#     hannanum = Hannanum()\n",
    "#     hanNouns = hannanum.nouns(removedoc)\n",
    "#     vect = CountVectorizer(ngram_range=(1, 2))\n",
    "#     words = \" \".join(hanNouns)\n",
    "#     count = vect.fit([words])\n",
    "#     candidate = count.get_feature_names_out()\n",
    "\n",
    "#     # print(candidate)\n",
    "\n",
    "#     doc_embedding = model.encode([removedoc])\n",
    "#     candidate_embeddings = model.encode(candidate)\n",
    "#     result: list = mmr(\n",
    "#         doc_embedding, candidate_embeddings, candidate, top_n=20, diversity=0.2\n",
    "#     )\n",
    "\n",
    "#     items = []\n",
    "#     for item in result:\n",
    "#         items.extend(item.split(\" \"))\n",
    "\n",
    "#     # Stopwords remove\n",
    "#     items = removeStopwords(items, stopwords)\n",
    "#     hanNouns = removeStopwords(hanNouns, stopwords)\n",
    "\n",
    "#     bertInfo = pd.DataFrame(items.split(\" \"))\n",
    "#     keyWordInfo = pd.DataFrame(hanNouns.split(\" \"))\n",
    "\n",
    "#     keyWords = (\n",
    "#         pd.concat([bertInfo, keyWordInfo], axis=0)\n",
    "#         .groupby(by=0)\n",
    "#         .size()\n",
    "#         .sort_values(ascending=False)\n",
    "#         .index.tolist()\n",
    "#     )\n",
    "\n",
    "#     keyWords = list(filter(lambda a: a if len(a) > 1 else None, keyWords))\n",
    "#     # engList = pd.DataFrame(findEng(doc)).value_counts().sort_values(ascending=False)[:5]\n",
    "#     return keyWords[:20]\n",
    "\n",
    "\n",
    "# text = bookInfo.iloc[500].dropna().astype(str).tolist()\n",
    "\n",
    "# text = \" \".join(text)\n",
    "\n",
    "# result = testbookInfoExtraction(text, stopwords, model)\n",
    "\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster._k_means_common as kmeans\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
