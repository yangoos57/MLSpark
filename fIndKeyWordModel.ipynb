{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KoNLPy 형태소 분석기 선정\n",
    "\n",
    "### 대상\n",
    "1. hannanum\n",
    "2. kkma\n",
    "3. okt\n",
    "\n",
    "### 선정 방법\n",
    "\n",
    "책 10권에 대해 각각 10개의 키워드 선정\n",
    "hannanum,kkma,okt 명사추출 기능으로 해당 키워드가 구분되는지 체크 \n",
    "\n",
    "### 도서목록\n",
    "1. 리액트를 다루는 기술 = The art of React : 실무에서 알아야 할 기술은 따로 있다!\n",
    "\n",
    "2. (Do it!) 장고 + 부트스트랩 파이썬 웹 개발의 정석 : 만들면서 배우는 웹 개발 A to Z\n",
    "3. 머신러닝 디자인 패턴 : 효율적인 머신러닝 파이프라인과 MLOps를 구축하는 30가지 디자인 패턴\n",
    "4. 핸즈온 머신러닝\n",
    "5. 파이썬을 이용한 데이터 분석의 정석 : 넘파이, 판다스, 맷플롯립과 실전 예제로 배우는\n",
    "6. 스파크 완벽 가이드 : 스파크를 활용한 빅데이터 처리와 분석의 모든 것\n",
    "7. 처음 시작하는 딥러닝\n",
    "8. 컴퓨터 사이언스 부트캠프 with 파이썬\n",
    "9. 케라스 창시자에게 배우는 딥러닝\n",
    "10. 처음 배우는 리액트 네이티브 크로스 플랫폼 앱 개발을 위한 실전 입문서\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum,Okt,Kkma\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 비교에 사용 될 도서 10권 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002s][warning][os,thread] Attempt to protect stack guard pages failed (0x00000001693d8000-0x00000001693e4000).\n",
      "[0.002s][warning][os,thread] Attempt to deallocate stack guard pages failed.\n"
     ]
    }
   ],
   "source": [
    "bookinfo = pd.read_csv('./data/bookInfo12.csv',encoding='cp949')\n",
    "testBooksISBN = [9791160508796,9791163032069,9791162244845,9791162242964,9791186710708,9791162241288,9791162243343,9791160504095,9791160505979,9791162243879]\n",
    "testBooks = bookinfo[bookinfo['col1'].isin(testBooksISBN)]\n",
    "han = Hannanum()\n",
    "\n",
    "\n",
    "def mergeListToString(wordList:list) -> str :\n",
    "    '''\n",
    "    wordList = item.astype(str).tolist()\n",
    "    item = pd.Series()\n",
    "    '''\n",
    "    str_list = [re.sub('\\d','',str(a)) for a in wordList]\n",
    "    str_list = list(filter(None, str_list))\n",
    "    result :str = ' '.join(str_list)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = books.iloc[1].tolist()\n",
    "def TFIDF(wordsList) :\n",
    "    from operator import itemgetter\n",
    "\n",
    "    # str_list = [re.sub('\\d','',str(a)) for a in wordList]\n",
    "    # str_list = list(filter(None, str_list))\n",
    "\n",
    "    # han = Hannanum()\n",
    "    # word = ' '.join(str_list)\n",
    "    # konlpword = han.nouns(word)\n",
    "    # konlpword = ' '.join(konlpword)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    sp_matrix = vectorizer.fit_transform(wordsList)\n",
    "\n",
    "    # a,b\n",
    "    a = np.array(vectorizer.get_feature_names_out())\n",
    "    b = sp_matrix.toarray()[0]\n",
    "    unique, counts = np.unique(b, return_counts=True)\n",
    "\n",
    "    ### Top 10 추출\n",
    "    k = 0\n",
    "    for num in range(1,100) :\n",
    "        if k < 10 :\n",
    "            k += counts[-num]\n",
    "        else :\n",
    "            break\n",
    "\n",
    "    result =[(a,b) for a,b in zip(a,b) if b >= unique[-num]]            \n",
    "    result = sorted(result,key=itemgetter(1),reverse=True)\n",
    "    return result\n",
    "\n",
    "wordsList=[mergeListToString(i[1]) for i in testBooks.iterrows()]\n",
    "konlpyWordsForTFIDF = list(map(lambda x : ' '.join(han.nouns(x)),wordsList ))\n",
    "k = TFIDF(konlpyWordsForTFIDF)\n",
    "TFIDFKeyword = list(map(lambda x : x[0],k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 5000개 적용 및 MultiProcessing 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "#도서별 모든 문장 하나로 합치기\n",
    "wordsList=[mergeListToString(i[1].astype(str).tolist()) for i in bookinfo.iterrows()] \n",
    "\n",
    " # 모든 문장 형태소 분석\n",
    "konlpyWordsForTFIDF = list(map(lambda x : ' '.join(han.nouns(x)),wordsList ))\n",
    "\n",
    "\n",
    "# 형태소 분석 결과 비지도학습\n",
    "vectorizer = TfidfVectorizer()\n",
    "sp_matrix = vectorizer.fit_transform(konlpyWordsForTFIDF) \n",
    "\n",
    "# 결과 추출\n",
    "a = np.array(vectorizer.get_feature_names_out()) # n개 키워드\n",
    "b = sp_matrix.toarray() ## 책 권수 만큼 array 생성(5237개). / 개별 array shape = shape(n,)\n",
    "\n",
    "# Keyword Top 10 추출\n",
    "result = []\n",
    "for arr in b :\n",
    "    unique, counts = np.unique(arr, return_counts=True)\n",
    "    ### Keyword Top 10 추출\n",
    "    k = 0\n",
    "    for num in range(1,100) :\n",
    "        if k < 10 :\n",
    "            k += counts[-num]\n",
    "        else :\n",
    "            break\n",
    "\n",
    "    try : \n",
    "        itemList =[(name,percent) for name,percent in zip(a,arr) if percent >= unique[-num]]            \n",
    "        itemList = sorted(itemList,key=itemgetter(1),reverse=True)\n",
    "        result.append(itemList)\n",
    "    except:\n",
    "        result.append(None)\n",
    "\n",
    "# 추출 결과를 column에 넣기 위한 전처리\n",
    "TFIDFKeyword =[]\n",
    "for item in result:\n",
    "    list1=[]\n",
    "    for x in item:\n",
    "        list1.append(x[0])\n",
    "    TFIDFKeyword.append(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['도커', '컨테이너', '실습', '쿠버네티스', '컴포즈', '매니페스트', '커맨드', '파드', '리눅스용', '설치', '실행']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 개별 단어에 Top 10 확보\n",
    "# TF-IDF 단점 : 매달 TF-IDF를 돌려야함. 비효율적이라 판단\n",
    "TFIDFKeyword[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete wordsList Load!!\n"
     ]
    }
   ],
   "source": [
    "def mergeListToString(item:pd.Series) :\n",
    "    wordList = item.astype(str).tolist()\n",
    "    str_list = [re.sub('\\d','',str(a)) for a in wordList]\n",
    "    str_list = list(filter(None, str_list))\n",
    "    result = ' '.join(str_list)\n",
    "    return result\n",
    "\n",
    "wordsList=[mergeListToString(i[1]) for i in bookinfo.iterrows()]\n",
    "print('Complete wordsList Load!!')\n",
    "konlpyWords = list(map(lambda x : han.nouns(x),wordsList ))\n",
    "embedding_model = Word2Vec(sentences=konlpyWords, window = 2, min_count=50, workers=7, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습된 vec 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model.wv.sa ve_word2vec_format('booksTest1') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"booksTest1\") # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "kkk = pd.read_csv('./data/keywordExtraction.csv',encoding='cp949')\n",
    "lists = kkk['keyword'].tolist()\n",
    "\n",
    "def changeStringToList(strList) :\n",
    "    strList = strList.replace(' ',', ')\n",
    "    result = np.array(ast.literal_eval(strList))\n",
    "    \n",
    "    return ast.literal_eval(strList)\n",
    "\n",
    "result = list(map(changeStringToList,lists))\n",
    "\n",
    "# embedding_model = Word2Vec(sentences=result, window = 2, min_count=50, workers=7, sg=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복값 찾기\n",
    "def findOverlapNum(keywordsOfBook:list,keywordsWord2Vec):\n",
    "    return sum(np.in1d(keywordsOfBook,keywordsWord2Vec))\n",
    "\n",
    "\n",
    "\n",
    "searchedKeyword = ['자연어','파이썬']\n",
    "keywordsWord2Vec = loaded_model.most_similar(positive=searchedKeyword,topn=20)\n",
    "sums = np.array(list(map(lambda x : findOverlapNum(x,keywordsWord2Vec) ,result)))\n",
    "kkkk= kkk.copy()\n",
    "kkkk['sums']=sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>도서명</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>딥러닝 텐서플로 교과서 :기초부터 CNN, RNN, 시계열 분석, 성능 최적화, 자...</td>\n",
       "      <td>9791165215477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>(기초부터 배우는) 인공지능</td>\n",
       "      <td>9788931582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>머신 러닝을 위한 수학 with 파이썬, R - 딥러닝에 필요한 수학만 골라 담았다!</td>\n",
       "      <td>9791165212537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>자연어 처리 쿡북 with 파이썬</td>\n",
       "      <td>9791161752655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>머신 러닝 교과서 with 파이썬, 사이킷런, 텐서플로</td>\n",
       "      <td>9791160507966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   도서명           ISBN\n",
       "127  딥러닝 텐서플로 교과서 :기초부터 CNN, RNN, 시계열 분석, 성능 최적화, 자...  9791165215477\n",
       "202                                   (기초부터 배우는) 인공지능   9788931582819\n",
       "305    머신 러닝을 위한 수학 with 파이썬, R - 딥러닝에 필요한 수학만 골라 담았다!  9791165212537\n",
       "346                                 자연어 처리 쿡북 with 파이썬  9791161752655\n",
       "478                     머신 러닝 교과서 with 파이썬, 사이킷런, 텐서플로  9791160507966"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkkk[kkkk['sums'] > 2][['도서명','ISBN']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
